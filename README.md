# ü¶â Projeto Jacurutu

> **Status do Projeto:** üöÄ MVP Funcional (v1.0)

**O Jacurutu (Coruj√£o-orelhudo) √© a maior ave de rapina noturna do Brasil. Conhecida por sua vis√£o e audi√ß√£o agu√ßadas, ela monitora seus alvos antes da ca√ßa. A ideia do projeto √© a mesma: monitorar a "floresta" de dados de gastos p√∫blicos para encontrar as transa√ß√µes que fogem do padr√£o.**

## 1. Vis√£o Geral

Este projeto utiliza Ci√™ncia de Dados para analisar os gastos dos Cart√µes de Pagamento do Governo Federal (CPGF).

Nosso objetivo n√£o √© apenas *encontrar* transa√ß√µes estranhas, mas **prioriz√°-las** de forma inteligente. Para isso, constru√≠mos um sistema que combina o **n√≠vel de "estranheza"** (detectado por um *Ensemble* de IA) com o **valor financeiro (risco)**. O resultado final √© um *dashboard* interativo onde um auditor pode investigar os casos mais relevantes com efici√™ncia e rapidez.

## 2. Fonte dos Dados

A base de dados principal √© o extrato detalhado dos cart√µes corporativos do Governo Federal, cobrindo o per√≠odo de 2023 at√© o presente.

* **Fonte:** Portal da Transpar√™ncia
* **URL de Download:** [Portal da Transpar√™ncia - CPGF](https://portaldatransparencia.gov.br/download-de-dados/cpgf)
* **Dicion√°rio dos Dados:** [Dicion√°rio de Dados - CPGF](https://portaldatransparencia.gov.br/dicionario-de-dados/cpgf)

## 3. Arquitetura e Tecnologias

O projeto adota uma **arquitetura desacoplada** para garantir alta performance no dashboard:

1.  **Backend (ETL Offline):** Scripts pesados que rodam em batch, treinam os modelos e geram um arquivo otimizado (`.parquet`).
2.  **Frontend (Dashboard Online):** Aplica√ß√£o leve que apenas l√™ os dados processados, garantindo carregamento instant√¢neo.

### Stack Tecnol√≥gica
* **Linguagem:** [Python 3.12.9](https://www.python.org/)
* **Processamento:** [Pandas](https://pandas.pydata.org/) & [PyArrow](https://arrow.apache.org/) (Formato Parquet)
* **Machine Learning:** [Scikit-learn](https://scikit-learn.org/)
    * **Isolation Forest** (Detec√ß√£o global)
    * **Local Outlier Factor (LOF)** (Detec√ß√£o local/densidade)
* **Dashboard:** [Streamlit](https://streamlit.io/)
* **Visualiza√ß√£o:** [Plotly](https://plotly.com/) (Gr√°ficos Interativos) & [Folium](https://python-visualization.github.io/folium/) (Mapas de Calor)

## 4. Pipeline do Projeto: O Roteiro da Ca√ßa

Nossa metodologia segue um roteiro estruturado para transformar dados brutos em *insights* acion√°veis.

### 4.1. Ingest√£o e Limpeza Avan√ßada
* **Consolida√ß√£o:** Unifica√ß√£o de arquivos CSV mensais.
* **Rastreabilidade:** Adi√ß√£o da coluna `ARQUIVO ORIGEM` para auditoria da fonte.
* **Tratamento de Sigilo:** Identifica√ß√£o e tratamento de transa√ß√µes sigilosas (sem data/favorecido), com imputa√ß√£o de datas cont√°beis.
* **Enriquecimento Geogr√°fico (NLP):** Algoritmo de processamento de texto que extrai a localiza√ß√£o (Estado/UF) a partir do nome da Unidade Gestora, permitindo a cria√ß√£o de mapas de calor.

### 4.2. Engenharia de Features
Para ensinar a IA o que √© "estranho", criamos contextos matem√°ticos:
* **Contexto Temporal:** Cria√ß√£o de flags para datas imputadas.
* **Frequency Encoding:** Transforma√ß√£o de vari√°veis categ√≥ricas (√ìrg√£o, Favorecido) em num√©ricas baseadas na raridade.
* **Golden Features (Ratios):** C√°lculo de raz√µes estat√≠sticas (ex: `Valor da Transa√ß√£o / M√©dia do √ìrg√£o no M√™s`). Isso permite detectar desvios sutis que escapam √† an√°lise de valor bruto.

### 4.3. Modelagem (O "Comit√™ de Detetives")
Utilizamos uma estrat√©gia de **Ensemble N√£o Supervisionado**:

* **Detetive 1 (`Isolation Forest`):** Foca em isolar anomalias globais e valores extremos.
* **Detetive 2 (`Local Outlier Factor`):** Analisa a densidade local, identificando pontos isolados em rela√ß√£o aos seus vizinhos imediatos.
    * *Destaque T√©cnico:* Implementa√ß√£o de **_Jittering_** (ru√≠do estat√≠stico controlado) para lidar com a alta duplicidade de valores exatos em transa√ß√µes governamentais.

### 4.4. Prioriza√ß√£o e Investiga√ß√£o
O score t√©cnico sozinho n√£o √© suficiente para auditoria p√∫blica. Criamos o **_Priority Score_**:

$$Prioridade = (0.7 \times ScoreTecnico) + (0.3 \times RiscoFinanceiro)$$

Isso garante que uma anomalia estat√≠stica de R$ 10,00 n√£o tenha a mesma aten√ß√£o que uma de R$ 100.000,00.

## 5. Como Executar o Projeto

1.  **Instala√ß√£o das depend√™ncias:**
    ```bash
    pip install -r requirements.txt
    ```
2.  **Execu√ß√£o do ETL (Gera√ß√£o dos Dados):**
    Este passo processa os CSVs brutos, treina os modelos e salva o arquivo `.parquet`.
    ```bash
    python run_etl.py
    ```
3.  **Execu√ß√£o do Dashboard:**
    ```bash
    streamlit run functions/front/app.py
    ```

## 6. Limita√ß√µes e Riscos

* **Raridade vs. Ilegalidade:** O modelo aponta o que √© *at√≠pico*. Um gasto pode ser raro (ex: compra √∫nica de equipamento) e perfeitamente legal.
* **Sazonalidade:** O setor p√∫blico possui ciclos fortes (ex: encerramento de exerc√≠cio fiscal em dezembro).
* **Cold Start:** Novos fornecedores podem ter scores de anomalia inicialmente altos at√© que o sistema aprenda seu padr√£o.

## 7. Roadmap (Progresso)

* ‚úÖ **An√°lise Explorat√≥ria (EDA):** Compreens√£o profunda das distribui√ß√µes e sazonalidade.
* ‚úÖ **Limpeza de Dados (ETL):** Pipeline robusto com extra√ß√£o geogr√°fica e tratamento de sigilo.
* ‚úÖ **Modelagem Ensemble:** Implementa√ß√£o e combina√ß√£o de Isolation Forest + LOF.
* ‚úÖ **Dashboard v1:** Interface em Streamlit com mapas, filtros e exporta√ß√£o (Excel/CSV).
* ‚úÖ **Arquitetura de Produ√ß√£o:** Separa√ß√£o do ETL (`run_etl.py`) do Frontend.

### üîÆ Melhorias Futuras
* **Autoencoder (_Deep Learning_):** Implementar redes neurais para reconstru√ß√£o de padr√µes complexos n√£o lineares.
* **Previs√£o Or√ßament√°ria:** Modelos de s√©ries temporais (Prophet/ARIMA) para prever gastos futuros.
