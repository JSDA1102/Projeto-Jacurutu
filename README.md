# ü¶â Projeto Jacurutu

> **Status do Projeto:** üöß Em Andamento üöß

**O Jacurutu (Coruj√£o-orelhudo) √© a maior ave de rapina noturna do Brasil. Conhecida por sua vis√£o e audi√ß√£o agu√ßadas, ela monitora seus alvos antes da ca√ßa. A ideia do projeto √© a mesma: monitorar a "floresta" de dados de gastos p√∫blicos para encontrar as transa√ß√µes que fogem do padr√£o.**

## 1. Vis√£o Geral

Este projeto utiliza Ci√™ncia de Dados para analisar os gastos dos Cart√µes de Pagamento do Governo Federal (CPGF).

Nosso objetivo n√£o √© apenas *encontrar* transa√ß√µes estranhas, mas **prioriz√°-las** de forma inteligente. Para isso, constru√≠mos um sistema que combina o **n√≠vel de "estranheza"** (detectado por um *Ensemble* de IA) com o **valor financeiro (risco)**. O resultado final √© um *dashboard* interativo onde um auditor pode investigar os casos mais relevantes com efici√™ncia.

## 2. Fonte dos Dados

A base de dados principal √© o extrato detalhado dos cart√µes corporativos do Governo Federal, cobrindo o per√≠odo de 2023 at√© o presente.

* **Fonte:** Portal da Transpar√™ncia
* **URL de Download:** [Portal da Transpar√™ncia - CPGF](https://portaldatransparencia.gov.br/download-de-dados/cpgf)
* **Dicion√°rio dos Dados:** [Dicion√°rio de Dados - CPGF](https://portaldatransparencia.gov.br/dicionario-de-dados/cpgf)

## 3. Tecnologias Principais

* **[Python 3.12.9](https://www.python.org/)**
* **[Pandas](https://pandas.pydata.org/) & [PyArrow](https://arrow.apache.org/):** Para manipula√ß√£o de dados de alta performance e leitura de arquivos Parquet.
* **[Scikit-learn](https://scikit-learn.org/):** Para constru√ß√£o dos modelos de detec√ß√£o de anomalia.
    * **Isolation Forest** (Detec√ß√£o global)
    * **Local Outlier Factor (LOF)** (Detec√ß√£o local/densidade)
* **[Streamlit](https://streamlit.io/):** Para constru√ß√£o do painel de investiga√ß√£o (Dashboard).
* **[Geopandas](https://geopandas.org/) (Planejado):** Para visualiza√ß√£o geoespacial dos gastos.

## 4. Pipeline do Projeto: O Roteiro da Ca√ßa

Nossa metodologia segue um roteiro estruturado para transformar dados brutos em *insights* acion√°veis.

### 4.1. Ingest√£o e Limpeza Avan√ßada
* **Consolida√ß√£o:** Unifica√ß√£o de todos os arquivos CSV mensais.
* **Rastreabilidade:** Adi√ß√£o da coluna `ARQUIVO ORIGEM` para auditoria da fonte.
* **Tratamento de Sigilo:** Identifica√ß√£o e tratamento de 92.000+ transa√ß√µes sigilosas (sem data/favorecido), com imputa√ß√£o de datas cont√°beis para manuten√ß√£o da s√©rie temporal.
* **Enriquecimento Geogr√°fico (NLP):** Como a base original n√£o possui coluna de Estado (UF), desenvolvemos um algoritmo de processamento de texto que extrai a localiza√ß√£o a partir do nome da Unidade Gestora, identificando gastos regionais vs. centrais.

### 4.2. Engenharia de Features
Para ensinar a IA o que √© "estranho", criamos contextos matem√°ticos:
* **Contexto Temporal:** Cria√ß√£o de flags para datas imputadas.
* **Frequency Encoding:** Transforma√ß√£o de vari√°veis categ√≥ricas (√ìrg√£o, Favorecido) em num√©ricas baseadas na raridade de ocorr√™ncia.
* **Golden Features (Ratios):** C√°lculo de raz√µes estat√≠sticas (ex: `Valor da Transa√ß√£o / M√©dia do √ìrg√£o no M√™s`). Isso permite detectar desvios sutis que escapam √† an√°lise de valor bruto.

### 4.3. Modelagem (O "Comit√™ de Detetives")
Utilizamos uma estrat√©gia de **Ensemble** n√£o supervisionado.

* **Detetive 1 (`Isolation Forest`):** Foca em isolar anomalias globais e valores extremos.
* **Detetive 2 (`Local Outlier Factor` - LOF):** Analisa a densidade local.
    * *Destaque T√©cnico:* Implementamos **Jittering** (ru√≠do estat√≠stico) para lidar com a alta densidade de transa√ß√µes repetidas (comuns em gastos governamentais), garantindo a estabilidade matem√°tica do modelo.
* **Detetive 3 (`Autoencoder`):** (Planejado) Rede neural para reconstru√ß√£o de padr√µes complexos.

### 4.4. Prioriza√ß√£o e Investiga√ß√£o
O score t√©cnico n√£o √© suficiente para auditoria p√∫blica. Criamos o **Score de Prioridade**:

$$Prioridade = (0.7 \times ScoreTecnico) + (0.3 \times RiscoFinanceiro)$$

Isso garante que uma anomalia de R$ 10,00 n√£o tenha a mesma aten√ß√£o que uma de R$ 100.000,00.

## 5. M√©tricas de Avalia√ß√£o

Como n√£o temos r√≥tulos de "fraude confirmada", avaliamos pela relev√¢ncia:
* **Valida√ß√£o Humana:** Auditoria manual das **Top 200** transa√ß√µes suspeitas.
* **M√©trica Chave (`Precision@k`):** "Das Top 100 anomalias apontadas, quantas s√£o dignas de investiga√ß√£o profunda?"

## 6. Limita√ß√µes e Riscos

* **Raridade vs. Ilegalidade:** O modelo aponta o que √© *at√≠pico*. Um gasto pode ser raro (ex: compra √∫nica de um equipamento) e perfeitamente legal.
* **Sazonalidade:** O setor p√∫blico possui ciclos fortes (ex: "correria" de gastos em dezembro).
* **Cold Start:** Novos fornecedores podem ter scores de anomalia inicialmente altos at√© que o sistema aprenda seu padr√£o.

## 7. Entreg√°veis

### Obrigat√≥rios (Core)
1.  **Pipeline de Dados:** Scripts de limpeza e engenharia de features automatizados.
2.  **Modelos Treinados:** Ensemble (IF + LOF) gerando scores de anomalia.
3.  **Dashboard Interativo:** Ferramenta em Streamlit para consumo dos dados pelo auditor.

### Opcionais
1.  **An√°lise Geoespacial:** Mapas de calor de gastos suspeitos.
2.  **Previs√£o de Gastos:** Modelos de s√©rie temporal para or√ßamento futuro.

## 8. Roadmap (Progresso)

* ‚úÖ **An√°lise Explorat√≥ria (EDA):** Compreens√£o profunda das distribui√ß√µes e sazonalidade.
* ‚úÖ **Limpeza de Dados (ETL):** Pipeline robusto com extra√ß√£o geogr√°fica e tratamento de sigilo.
* ‚úÖ **Baseline Model (LOF):** Implementado com Feature Engineering avan√ßada e Jittering.
* üî≤ **Baseline Model (Isolation Forest):** Em desenvolvimento.
* üî≤ **Ensemble:** Combina√ß√£o dos scores.
* üî≤ **Dashboard v1:** Desenvolvimento da interface em Streamlit.
* üî≤ **Valida√ß√£o Manual:** Auditoria dos resultados.
