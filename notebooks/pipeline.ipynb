{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca86a87a",
   "metadata": {},
   "source": [
    "## üïµÔ∏è Anomaly Detection Pipeline: Execution and Scoring\n",
    "This notebook serves as the final stage of the anomaly detection process. It executes the full data and model pipeline, merges the results from the four model runs (LOF and Isolation Forest, both on normal and classified data), normalizes the anomaly scores, and calculates a final Priority Score used for manual review and triage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7d45f2",
   "metadata": {},
   "source": [
    "## 1. Setup and Core Functions\n",
    "We import all necessary libraries and define the three core functions that manage the pipeline's execution and scoring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb50a7f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eeadb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e60a6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from functions.clean_df import load_and_combine_csvs,clean_dataframe\n",
    "from functions.state_imput import apply_state_estimation\n",
    "from functions.feature_engineering import feature_engineering\n",
    "from functions.preprocessing import get_preprocessor\n",
    "from functions.models import run_lof_normal, run_lof_classified, run_if_normal, run_if_classified\n",
    "from functions.pipeline import run_pipeline, combine_dataframes\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacbfa0f",
   "metadata": {},
   "source": [
    "## 2. Run Pipeline\n",
    "\n",
    "The cell below initializes the path to the raw data and starts executing our pipeline. The function run_pipeline that comes as a result of it orchestrates the entire process: data cleaning, feature engineering, and the execution of all four anomaly detection models (LOF/IF on both normal and classified subsets).\n",
    "\n",
    "The resulting result_dict now holds the four DataFrames required for the final scoring and merging stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17d2fe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = '../raw_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "984c698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = load_and_combine_csvs(raw_path)\n",
    "df_clean = clean_dataframe(df_raw)\n",
    "df_state = apply_state_estimation(df_clean)\n",
    "df_feature_engineering = feature_engineering(df_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48ca46ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {\n",
    "    'lof_classified': run_lof_classified(df_feature_engineering),\n",
    "    'lof_normal': run_lof_normal(df_feature_engineering),\n",
    "    'if_classified': run_if_classified(df_feature_engineering),\n",
    "    'if_normal': run_if_normal(df_feature_engineering)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "063ae7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lof_classified = result_dict['lof_classified']\n",
    "df_lof_normal = result_dict['lof_normal']\n",
    "df_if_classified = result_dict['if_classified']\n",
    "df_if_normal = result_dict['if_normal']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4069a7",
   "metadata": {},
   "source": [
    "## 2.1 Final run_pipeline function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985874d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(raw_data):\n",
    "    \"\"\"\n",
    "    Runs the entire data processing and modeling pipeline.\n",
    "\n",
    "    Parameters\n",
    "    raw_data : Path to directory with CSVs.\n",
    "\n",
    "    Returns\n",
    "    Dictionary of length 4:\n",
    "        - Output of run_lof_classified(df_feature_engineering)\n",
    "        - Output of run_lof_normal(df_feature_engineering)\n",
    "        - Output of run_if_classified(df_feature_engineering)\n",
    "        - Output of run_if_normal(df_feature_engineering)\n",
    "    \"\"\"\n",
    "    df_raw = load_and_combine_csvs(raw_data)\n",
    "    df_clean = clean_dataframe(df_raw)\n",
    "    df_state = apply_state_estimation(df_clean)\n",
    "    df_feature_engineering = feature_engineering(df_state)\n",
    "\n",
    "    return {\n",
    "    'lof_classified': run_lof_classified(df_feature_engineering),\n",
    "    'lof_normal': run_lof_normal(df_feature_engineering),\n",
    "    'if_classified': run_if_classified(df_feature_engineering),\n",
    "    'if_normal': run_if_normal(df_feature_engineering)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e597c160",
   "metadata": {},
   "source": [
    "## 3. Combining dataframes and normalizing their score\n",
    "This section executes the combine_dataframes function, which is the consolidation and score normalization step.\n",
    "\n",
    "Consolidation and Score Unification\n",
    "This stage is crucial because the four model results are based on two different data partitions (confidential vs. non-confidential).\n",
    "\n",
    "Combination: The combine helper function first merges the respective classified and normal subsets for LOF and IF models (e.g., df_lof_classified + df_lof_normal), creating a unified, full-size result for each method. It generates a sequential ID to serve as the stable key for the final join.\n",
    "\n",
    "Merging: The function then performs the final merge, combining the full feature set from the LOF results (df_lof_full) with only the specific scores and labels from the IF results (df_if_specific) using the generated ID.\n",
    "\n",
    "Score Alignment & Normalization: The raw scores are transformed to represent risk magnitude (higher score = higher risk). The IF score is inverted (1 - Score), and the LOF score's absolute value is taken.\n",
    "\n",
    "Finally, both scores are normalized to the $[-1, 1]$ range using MinMaxScaler. This ensures both models contribute equally to the final risk calculation, regardless of their original score distribution.\n",
    "\n",
    "The output, df_combined, is the single, integrated DataFrame containing all original features and the four normalized model scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcc5742",
   "metadata": {},
   "source": [
    "1. Setup and Helper Function Definition - This cell defines the necessary imports and the combine helper function which is essential for merging your disjoint data subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3696c95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Extracted 4 model result DataFrames and defined the 'combine' helper.\n"
     ]
    }
   ],
   "source": [
    "def combine(df1, df2, label_cols):\n",
    "    \"\"\"Combines two disjoint model result DFs, creates a sequential ID, and returns full and specific DFs.\"\"\"\n",
    "    # Concatenate, drop duplicates, and reset index\n",
    "    df = pd.concat([df1, df2], ignore_index=True).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # Create Sequential ID (used as the stable merge key)\n",
    "    df[\"ID\"] = df.index + 1\n",
    "\n",
    "    # Rearrange columns\n",
    "    cols = [\"ID\"] + [c for c in df.columns if c != \"ID\"]\n",
    "    df = df[cols]\n",
    "\n",
    "    # df_specific is used for merging only the score/label columns\n",
    "    df_specific = df[[\"ID\"] + label_cols]\n",
    "    return df, df_specific\n",
    "\n",
    "print(\"Setup complete. Extracted 4 model result DataFrames and defined the 'combine' helper.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b20602",
   "metadata": {},
   "source": [
    "2. Process and Merge LOF and IF Results - This cell uses the combine function to prepare the LOF and IF data and then performs the central merge operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a492e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOF and IF results merged into df_combined. Total rows: 307307.\n"
     ]
    }
   ],
   "source": [
    "# Processing LOF: Creates a full DataFrame with all features and LOF scores\n",
    "df_lof_full, df_lof_specific = combine(\n",
    "    df_lof_classified, df_lof_normal,\n",
    "    label_cols=[\"LOF_LABEL\", \"LOF_SCORE\"]\n",
    ")\n",
    "\n",
    "# Processing IF: Creates a specific DataFrame with ID and IF scores/labels\n",
    "df_if_full, df_if_specific = combine(\n",
    "    df_if_classified, df_if_normal,\n",
    "    label_cols=[\"IF_LABEL\", \"IF_SCORE\"]\n",
    ")\n",
    "\n",
    "# Final merge: Merges the IF scores/labels onto the LOF full DataFrame using the common \"ID\".\n",
    "df_combined = df_lof_full.merge(df_if_specific, on=\"ID\", how=\"inner\")\n",
    "\n",
    "print(f\"LOF and IF results merged into df_combined. Total rows: {len(df_combined)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82978dd",
   "metadata": {},
   "source": [
    "3. Align Risk Magnitude - This step prepares the raw scores for normalization by ensuring that a higher numerical value always represents a higher risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b92a1e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw scores transformed to RISK_IF_SCORE and RISK_LOF_SCORE (0 to 1 scale).\n"
     ]
    }
   ],
   "source": [
    "# IF_SCORE: Assuming lower score = higher risk. Invert to align risk magnitude (1 - Score).\n",
    "df_combined['RISK_IF_SCORE'] = 1 - df_combined['IF_SCORE']\n",
    "\n",
    "# LOF_SCORE: More negative is higher risk. Take the absolute value for magnitude.\n",
    "df_combined['RISK_LOF_SCORE'] = df_combined['LOF_SCORE'].abs()\n",
    "\n",
    "print(\"Raw scores transformed to RISK_IF_SCORE and RISK_LOF_SCORE (0 to 1 scale).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1516c95",
   "metadata": {},
   "source": [
    "4. Normalize Scores - This cell applies the MinMaxScaler to normalize both risk scores to the range $[-1, 1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d46d301d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOF_SCORE_NORM and IF_SCORE_NORM successfully created (range [-1, 1]).\n"
     ]
    }
   ],
   "source": [
    "# Initialize scaler for the range [-1, 1]\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "# Normalize LOF Risk Score\n",
    "df_combined['LOF_SCORE_NORM'] = scaler.fit_transform(df_combined[['RISK_LOF_SCORE']])\n",
    "\n",
    "# Normalize IF Risk Score\n",
    "df_combined['IF_SCORE_NORM'] = scaler.fit_transform(df_combined[['RISK_IF_SCORE']])\n",
    "\n",
    "print(\"LOF_SCORE_NORM and IF_SCORE_NORM successfully created (range [-1, 1]).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ea3140",
   "metadata": {},
   "source": [
    "5. Cleanup - The final step cleans up the temporary and redundant score columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05d7c90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermediate and raw score columns dropped.\n",
      "df_combined is ready for the final priority score calculation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LOF_SCORE_NORM</th>\n",
       "      <th>IF_SCORE_NORM</th>\n",
       "      <th>VALOR TRANSA√á√ÉO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.999998</td>\n",
       "      <td>-0.159904</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.999999</td>\n",
       "      <td>-0.239186</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.999998</td>\n",
       "      <td>-0.354873</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.999999</td>\n",
       "      <td>-0.093496</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.999999</td>\n",
       "      <td>-0.151828</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LOF_SCORE_NORM  IF_SCORE_NORM  VALOR TRANSA√á√ÉO\n",
       "0   1       -0.999998      -0.159904           1000.0\n",
       "1   2       -0.999999      -0.239186            350.0\n",
       "2   3       -0.999998      -0.354873            250.0\n",
       "3   4       -0.999999      -0.093496            300.0\n",
       "4   5       -0.999999      -0.151828            500.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clean up intermediate columns (RISK_...) and the raw score columns (LOF_SCORE, IF_SCORE)\n",
    "df_combined = df_combined.drop(columns=['RISK_LOF_SCORE', 'RISK_IF_SCORE', 'LOF_SCORE', 'IF_SCORE'])\n",
    "\n",
    "print(\"Intermediate and raw score columns dropped.\")\n",
    "print(\"df_combined is ready for the final priority score calculation.\")\n",
    "display(df_combined[['ID', 'LOF_SCORE_NORM', 'IF_SCORE_NORM', 'VALOR TRANSA√á√ÉO']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22b5bed",
   "metadata": {},
   "source": [
    "## 3. 1 Final combine_dataframes function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44c6f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dataframes(df_lof_classified, df_lof_normal, df_if_classified, df_if_normal):\n",
    "    \"\"\"\n",
    "    Combine the dataframes LOF and IF, creates ID, rearrange columns,\n",
    "    and merge final adding only specific columns.\n",
    "    \"\"\"\n",
    "    def combine(df1, df2, label_cols):\n",
    "        df = pd.concat([df1, df2], ignore_index=True).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "        df[\"ID\"] = df.index + 1\n",
    "\n",
    "        cols = [\"ID\"] + [c for c in df.columns if c != \"ID\"]\n",
    "        df = df[cols]\n",
    "\n",
    "        df_specific = df[[\"ID\"] + label_cols]\n",
    "        return df, df_specific\n",
    "\n",
    "    # Processing LOF\n",
    "    df_lof_full, df_lof_specific = combine(\n",
    "        df_lof_classified, df_lof_normal,\n",
    "        label_cols=[\"LOF_LABEL\", \"LOF_SCORE\"]\n",
    "    )\n",
    "    # Processing IF\n",
    "    df_if_full, df_if_specific = combine(\n",
    "        df_if_classified, df_if_normal,\n",
    "        label_cols=[\"IF_LABEL\", \"IF_SCORE\"]\n",
    "    )\n",
    "\n",
    "    # Final merge: LOF (all columns) + IF (specific columns)\n",
    "    df_final = df_lof_full.merge(df_if_specific, on=\"ID\", how=\"inner\")\n",
    "\n",
    "    # Normalization step\n",
    "    # IF_SCORE: Assuming lower score = higher risk. Invert to: Higher score = Higher risk.\n",
    "    df_final['RISK_IF_SCORE'] = 1 - df_final['IF_SCORE']\n",
    "\n",
    "    # LOF_SCORE: Already negative, where more negative is higher risk.\n",
    "    df_final['RISK_LOF_SCORE'] = df_final['LOF_SCORE'].abs()\n",
    "\n",
    "    # Normalize both risk scores to the range [-1, 1]\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "    # Reshape scores for MinMaxScaler and fit/transform\n",
    "    df_final['LOF_SCORE_NORM'] = scaler.fit_transform(df_final[['RISK_LOF_SCORE']])\n",
    "    df_final['IF_SCORE_NORM'] = scaler.fit_transform(df_final[['RISK_IF_SCORE']])\n",
    "\n",
    "    # Clean up intermediate columns\n",
    "    df_final = df_final.drop(columns=['RISK_LOF_SCORE', 'RISK_IF_SCORE'])\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af33ac3",
   "metadata": {},
   "source": [
    "## 4. Priority Score Calculation\n",
    "This section is about the risk engine of our pipeline. It takes the merged, normalized scores and weights them alongside the financial magnitude of the transaction to produce a final ranking score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141b8038",
   "metadata": {},
   "source": [
    "1. Technical Score (Model Consensus)\n",
    "\n",
    "The first step calculates the TECHNICAL_SCORE by taking the mean of the two normalized anomaly scores (LOF_SCORE_NORM and IF_SCORE_NORM). This score reflects the consensus of our machine learning models:\n",
    "\n",
    "It is high only if both models agree the transaction is statistically anomalous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "928b3a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Technical Scores (Mean)\n",
    "df_combined['TECHNICAL_SCORE'] = df_combined[['LOF_SCORE_NORM', 'IF_SCORE_NORM']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12761906",
   "metadata": {},
   "source": [
    "2. Financial Risk\n",
    "\n",
    "The FINANCIAL_RISK component is derived from the LOG_VALOR (log-transformed transaction value).\n",
    "\n",
    "MinMaxScaler is used to scale LOG_VALOR to the range $[0, 1]$. This converts the magnitude of the transaction into a standardized risk factor, where the largest transaction gets a risk score of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a288979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize LOG_VALOR to range [0, 1] to use it as a weighting factor\n",
    "log_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df_combined['FINANCIAL_RISK'] = log_scaler.fit_transform(df_combined[['LOG_VALOR']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5c7b8b",
   "metadata": {},
   "source": [
    "3. Final Priority Score and Ranking\n",
    "\n",
    "The final PRIORITY_SCORE is a weighted average of the two components:\n",
    "\n",
    "70% Weight (0.7): Applied to the TECHNICAL_SCORE (Statistical Evidence).\n",
    "\n",
    "30% Weight (0.3): Applied to the FINANCIAL_RISK (Impact/Magnitude).\n",
    "\n",
    "This prioritizes anomalies that are both statistically strange and have a significant financial impact. The DataFrame is then sorted by this score in descending order, making the highest-risk transactions appear at the top for immediate manual audit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9993f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Priority Calculation: (0.7 * Technical) + (0.3 * Financial Risk)\n",
    "df_combined['PRIORITY_SCORE'] = (\n",
    "    (0.7 * df_combined['TECHNICAL_SCORE']) +\n",
    "    (0.3 * df_combined['FINANCIAL_RISK'])\n",
    ")\n",
    "\n",
    "# Order by priority score\n",
    "df = df_combined.sort_values(by='PRIORITY_SCORE', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd53eaae",
   "metadata": {},
   "source": [
    "## 4.1 Final calculate_priority_score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ed26b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_priority_score(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Calculates the Technical Score, Financial Risk, and the final weighted\n",
    "    Priority Score for manual review.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the final PRIORITY_SCORE, sorted descending.\n",
    "    \"\"\"\n",
    "\n",
    "    # 3.1 Combine Technical Scores (Mean)\n",
    "    df['TECHNICAL_SCORE'] = df[['LOF_SCORE_NORM', 'IF_SCORE_NORM']].mean(axis=1)\n",
    "\n",
    "    # 3.2 Calculate Financial Risk and Final Weighted Priority Score\n",
    "\n",
    "    # Normalize LOG_VALOR to range [0, 1] to use it as a weighting factor\n",
    "    log_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    df['FINANCIAL_RISK'] = log_scaler.fit_transform(df[['LOG_VALOR']])\n",
    "\n",
    "    # Final Priority Calculation: (0.7 * Technical) + (0.3 * Financial Risk)\n",
    "    df['PRIORITY_SCORE'] = (\n",
    "        (0.7 * df['TECHNICAL_SCORE']) +\n",
    "        (0.3 * df['FINANCIAL_RISK'])\n",
    "    )\n",
    "\n",
    "    # Order by priority score\n",
    "    df = df.sort_values(by='PRIORITY_SCORE', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54952157",
   "metadata": {},
   "source": [
    "## 5. Inspect Final Structure and Missing Values\n",
    "This checks the column types, non-null counts, and confirms that the final score columns were created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e0ca31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DataFrame Information (df) ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 307307 entries, 0 to 307306\n",
      "Data columns (total 34 columns):\n",
      " #   Column                  Non-Null Count   Dtype         \n",
      "---  ------                  --------------   -----         \n",
      " 0   ID                      307307 non-null  int64         \n",
      " 1   C√ìDIGO √ìRG√ÉO SUPERIOR   307307 non-null  int64         \n",
      " 2   NOME √ìRG√ÉO SUPERIOR     307307 non-null  object        \n",
      " 3   C√ìDIGO √ìRG√ÉO            307307 non-null  int64         \n",
      " 4   NOME √ìRG√ÉO              307307 non-null  object        \n",
      " 5   C√ìDIGO UNIDADE GESTORA  307307 non-null  int64         \n",
      " 6   NOME UNIDADE GESTORA    307307 non-null  object        \n",
      " 7   ANO EXTRATO             307307 non-null  int64         \n",
      " 8   M√äS EXTRATO             307307 non-null  int64         \n",
      " 9   CPF PORTADOR            289417 non-null  object        \n",
      " 10  NOME PORTADOR           307307 non-null  object        \n",
      " 11  CNPJ OU CPF FAVORECIDO  307307 non-null  int64         \n",
      " 12  NOME FAVORECIDO         307307 non-null  object        \n",
      " 13  TRANSA√á√ÉO               307307 non-null  object        \n",
      " 14  DATA TRANSA√á√ÉO          289417 non-null  datetime64[ns]\n",
      " 15  VALOR TRANSA√á√ÉO         307307 non-null  float64       \n",
      " 16  ARQUIVO_ORIGEM          307307 non-null  object        \n",
      " 17  ESTADO_ESTIMADO         307307 non-null  object        \n",
      " 18  SIGILOSO                307307 non-null  int64         \n",
      " 19  ID_PORTADOR             289417 non-null  object        \n",
      " 20  FIM_SEMANA              307307 non-null  int64         \n",
      " 21  LOG_VALOR               307307 non-null  float64       \n",
      " 22  FREQ_NOME √ìRG√ÉO         307307 non-null  float64       \n",
      " 23  FREQ_ESTADO_ESTIMADO    307307 non-null  float64       \n",
      " 24  FREQ_NOME FAVORECIDO    307307 non-null  float64       \n",
      " 25  MEDIA_VALOR_ORGAO_MES   307307 non-null  float64       \n",
      " 26  RATIO_MES               307307 non-null  float64       \n",
      " 27  LOF_LABEL               307307 non-null  int64         \n",
      " 28  IF_LABEL                307307 non-null  int64         \n",
      " 29  LOF_SCORE_NORM          307307 non-null  float64       \n",
      " 30  IF_SCORE_NORM           307307 non-null  float64       \n",
      " 31  TECHNICAL_SCORE         307307 non-null  float64       \n",
      " 32  FINANCIAL_RISK          307307 non-null  float64       \n",
      " 33  PRIORITY_SCORE          307307 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(12), int64(11), object(10)\n",
      "memory usage: 79.7+ MB\n",
      "\n",
      "--- Check New Score Columns ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PRIORITY_SCORE</th>\n",
       "      <td>307307.0</td>\n",
       "      <td>-0.392042</td>\n",
       "      <td>0.108171</td>\n",
       "      <td>-0.580749</td>\n",
       "      <td>-0.475343</td>\n",
       "      <td>-0.417315</td>\n",
       "      <td>-0.325732</td>\n",
       "      <td>0.620270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TECHNICAL_SCORE</th>\n",
       "      <td>307307.0</td>\n",
       "      <td>-0.752262</td>\n",
       "      <td>0.138142</td>\n",
       "      <td>-0.999999</td>\n",
       "      <td>-0.858596</td>\n",
       "      <td>-0.782119</td>\n",
       "      <td>-0.667689</td>\n",
       "      <td>0.644897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FINANCIAL_RISK</th>\n",
       "      <td>307307.0</td>\n",
       "      <td>0.448471</td>\n",
       "      <td>0.105913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.378076</td>\n",
       "      <td>0.451681</td>\n",
       "      <td>0.521010</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count      mean       std       min       25%       50%  \\\n",
       "PRIORITY_SCORE   307307.0 -0.392042  0.108171 -0.580749 -0.475343 -0.417315   \n",
       "TECHNICAL_SCORE  307307.0 -0.752262  0.138142 -0.999999 -0.858596 -0.782119   \n",
       "FINANCIAL_RISK   307307.0  0.448471  0.105913  0.000000  0.378076  0.451681   \n",
       "\n",
       "                      75%       max  \n",
       "PRIORITY_SCORE  -0.325732  0.620270  \n",
       "TECHNICAL_SCORE -0.667689  0.644897  \n",
       "FINANCIAL_RISK   0.521010  1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"--- DataFrame Information (df) ---\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n--- Check New Score Columns ---\")\n",
    "display(df[['PRIORITY_SCORE', 'TECHNICAL_SCORE', 'FINANCIAL_RISK']].describe().T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jacurutu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
